Plant pathogens have evolved many dispersal mechanisms, using biotic or abiotic vectors or a combination of the two. Rain splash dispersal is known from a variety of fungi, and can be an efficient driver of crop epidemics, with infectious strains propagating rapidly among often genetically homogenous neighboring plants. Splashing is nevertheless a local dispersal process and spores taking the droplet ride seldom move farther than a few decimeters. In this study, we assessed rain splash dispersal of conidia of the yam anthracnose agent, Colletotrichum gloeosporioides, in an experimental setting using a rain simulator, with emphasis on the impact of soil contamination (i.e., effect of re-splashing events). Spores dispersed up to 50 cm from yam leaf inoculum sources, though with an exponential decrease with increasing distance. While few spores were dispersed via re-splash from spore-contaminated soil, the proportion deposited via this mechanism increased with increasing distance from the initial source. We found no soil contamination carryover from previous rains, suggesting that contamination via re-splashing from contaminated soils mainly occurred within single rains. We conclude that most dispersal occurs from direct splashing, with a weaker contribution of indirect dispersal via re-splash. 

Modelling the epidemiology of water yam anthracnose (Dioscorea alata) caused by the fungus Colletotrichum gloeosporioides is an important research goal, as it will allow the investigation of a wide range of scenarios of new practices to reduce the disease impact before experimentation in the field. Developing such a model requires a prior knowledge of the funguss response to the environmental conditions, which will be affected by pest management. In this work, we first measured the response of the fungus to the main physical environmental factors controlling its development, namely temperature (ranging from 18°C to 36°C) and wetness duration (from 2 h to 72 h). As response variables, we measured the percentage of formed appressoria (relative to the total number of spores), the length of the latent period (time lag between inoculation and first symptoms observed), and the rate of necrotic lesion extension (percentage of diseased leaf surface at different time steps). These variables allow us to estimate the effects of temperature and wetness duration on the success of infection (appressoria formation) and the subsequent rate of disease development (latent period length and lesion extension rate). The data were fitted to non-linear models chosen for their ability to describe the observed patterns. From our data and model analyses, we were able to estimate parameters such as the optimal and maximal temperatures (25-28°C and 36°C, respectively), the required wetness duration to reach 20 % of infection success and the time to reach 5 % disease severity as a function of temperature.

Anthracnose, caused by the fungus Colletotrichum gloeosporioides, is the most serious disease affecting water yam (Dioscorea alata) in the tropics. The objective of this study was to determine whether infected yam residues from the previous growing season could be a source of inoculum for the following yam crop. Residue decomposition and survival of the fungus on residues and in the soil were studied in a 161-day field experiment carried out during the dry season in Guadeloupe (French West Indies), which corresponds to the post-harvest period of yam. Artificially inoculated residues (leaves and stems) were put in litterbags, which were then either placed on the soil surface or buried at 0.1 m depth. Residue decomposition was also measured under laboratory conditions to obtain the parameters required by a model of decomposition. Residue decomposition in the field was greater in the first month, then steadily decreased until the end of the experiment. The decomposition rate decreased in the following order: buried leaves > surface leaves > buried stems > surface stems. The model described residue decomposition well, and the simulations showed that soil moisture and residue quality were key factors controlling decomposition in the field. Simulations also indicated that stems may stay more than five months in soil due to the low decomposition rate of the recalcitrant organic fraction. The number of C. gloeosporioides conidia diminished sharply in the first month, and the rate of decrease was similar to that of the labile fraction of residues as estimated by the model. Over this period, the number of conidia was higher in residues placed on the soil surface due to a larger amount of readily available substrate. Later, survival of C. gloeosporioides was mainly limited by the competition with microorganisms decomposing residues. Four months after the beginning of the experiment, 30% of the residues were still present in the field, mainly as stems, and the number of conidia represented less than 1% of the initial amount (e.g. 10^3 - 10^4 conidia g-1 dry matter). Pathogenicity of yam residues also sharply decreased after the first month and was higher for residues on the soil surface. By the end of the experiment, only stems on the soil surface exhibited pathogenicity. C. gloeosporioides could not be detected either in the soil in contact with the infected residues or in the control soil without residues. Given that the period between harvest and planting is approximately four months, our results indicated that stems on soil surface may contribute to the primary infection of yam with anthracnose.

Water yam (Dioscorea alata L.) is the most widely cultivated food yams. Despite its importance, its production is limited by anthracnose disease caused by Colletotrichum gloeosporioides (Penz.). The use of resistant yam varieties is the most reliable approach of management of this disease. The speed and precision of breeding can be improved by the development of genetic linkage maps which would provide the basis for locating and hence manipulating quantitative traits such as anthracnose resistance in breeding programmes. An F1 diploid population was developed by crossing Boutou a female clone (with field resistance to anthracnose) with Pyramide (susceptible). A linkage map was generated with 523 polymorphic markers from 26 AFLP primer combinations. The resulting map covered a total length of 1538cM and included 20 linkage groups. It is the most saturated of all genetic linkage maps of yam to date. QTL analysis of anthracnose resistance was performed based on response to two isolates of C. gloeosporioides. Resistance to anthracnose appeared to be inherited quantitatively. Using a LOD significance threshold of 2.6 we identified a total of nine QTLs for anthracnose resistance. The phenotypic variance explained by each QTL ranged from 7.0 to 32.9% whereas the total amount of phenotypic variation for anthracnose resistance explained by all significant QTLs varied from 26.4 to 73.7% depending on the isolate and the variable considered. These QTLs displayed isolate-specific resistance as well as broad spectrum resistance. The availability of molecular markers linked to the QTLs of anthracnose resistance will facilitate marker-assisted selection in breeding programmes.

Reactions of 60 water yam (Dioscorea alata) cultivars to three isolates of the yam anthracnose fungal pathogen (Colletotrichum gloeosporioides) were evaluated using tissue culture-derived whole-plant assay. Three disease parameters: single score on a scale of 0-6 at the seventh day after inoculation (SD7); area under the disease progress curve (AUDPC); and disease progress rate (Rd) were compared, and cultivars were classified into disease-response groups using a rank-sum method based on AUDPC scores for the two most virulent isolates. A wide range of variation in resistance of the D. alata cultivars, and significant effects of pathogen isolate and isolateâ€“cultivar interactions, were observed for all disease parameters. The three disease parameters were positively correlated; however, four cultivars showed great dispersions from the regression lines for comparisons of SD7 with the multiple assessments based AUDPC and Rd. The 60 cultivars were separated into resistant (n = 12), moderately resistant (n = 19), moderately susceptible (n = 18) and susceptible (n = 11) groups. The potential of the tissue culture-derived whole-plant assay to resistance breeding programmes and further understanding of the yam anthracnose pathosystem is discussed.

Studies were conducted to determine the timing and frequency of disease assessment required to effectively identify levels of resistance to yam anthracnose using tissue culture-derived whole plant inoculation assay. The effects of inoculation methods (paint brush and spray), and disease scoring methods [individual leaf area (ILA) and whole plant area (WPA)] were also assessed. Spray inoculation resulted in rapid infection and higher variations among yam genotypes, leading to earlier discrimination of genotypes than with the paintbrush method. Both the ILA and WPA scoring methods showed variation among yam genotypes, and association between the two methods gave a high positive correlation (r > 0.90). However, the WPA was faster and had the advantage of detecting differences in reactions of yam genotypes to less aggressive pathogen isolates to which the ILA method showed no variation. A single disease evaluation at 7 days after inoculation was as good as the area under the disease progress curve (AUDPC) and the disease progress rate (Rd) derived from multiple evaluations. However, a significant time-genotype interaction, suggests a need for more than a single assessment for effective comparison of genotypes. AUDPC derived from two assessments (5 and 7 DAI) was better than AUDPC from three assessments (5, 7 and 9 DAI) in separating genotypes reactions to a less aggressive pathogen isolate. This study showed that the use of spray inoculation method, the WPA scoring method, and AUDPC derived from two assessments (5 and 7 DAI) provided best conditions for evaluating yam genotypes for levels of anthracnose resistance with the tissue culture-derived whole plant assay

Ideotypes are a popular concept for plant breeders, who designate as such the ideal combinations of traits in a particular genotype to reach a pre-set production objective within a given socio-economic context. The historical, genetic view of ideotypes has been more recently extended to cover the design of plant genotypes for specific cropping systems (the agronomic view), or even the ideal combination of parameters, identified from formal or simulation modeling, to a specific agronomic problem (the modelling view). These different forms of ideotypes in turn lead to different strategies for breeding plants. This paper will briefly describe, analyse and discuss some applications of these ideotype views, using the specific case of architectural traits of plant and crop canopies to limit the epidemic development of pests and diseases in crops. It is not intended to be an exhaustive and objective review of the existing literature on plant ideotypes, but rather to express as an opinion paper the views discussed and elaborated among participants to the EpiArch network.

As any epidemic on plants is driven by the amount of susceptible tissue, and the distance between organs, any modification in the host population, whether quantitative or qualitative, can have an impact on the epidemic dynamics. In this paper we examine using examples described in the literature, the features of the host plant and the use of crop management which are likely to decrease diseases. We list the pathogen processes that can be affected by crop growth and architecture modifications and then determine how we can highlight the principal ones. In most cases, a reduction in plant growth combined with an increase in plant or crop porosity reduces infection efficiency and spore dispersal. Experimental approaches in semi-controlled conditions, with concomitant characterisation of the host, microclimate and disease, allow a better understanding and analysis of the processes impacted. Afterwards, the models able to measure and predict the effect of plant growth and architecture on epidemic behaviour are reviewed.

In order to investigate the impact of pea canopy architecture and development on microclimate and infection by Mycosphaerella pinodes, two field experiments were conducted in 2009 and 2010 at Le Rheu (France) to obtain canopies contrasted in height, closure dynamic, leaf area index (LAI) and leaf area density (LAD). Three pea cultivars (Athos, Antares, Gregor) were sown at two (80 and 40 seeds/m2 in 2009) and three densities (80, 40 and 30 seeds/m2 in 2010) and microclimatic sensors were located inside the canopy (at the bottom and in the middle) and outside. Two main sources of wetness were identified: rainfall and dew. During rainfall periods, average daily leaf wetness duration (LWD) was about 15 h, and 3 to 10 h longer inside than outside the canopies. LWD was positively correlated with LAI until canopy closure during these periods. During dry periods when dew was the only source of leaf wetness, average daily LWD was short, decreasing as the canopy developed. Shorter LWDs were observed at the base than at the mid-level of the canopies and longer LWDs were observed outside the canopy and inside the less dense canopies irrespective of the cultivar. LWD was negatively correlated with canopy height and LAI during these periods. Slow wind speeds were recorded inside the canopies (less than 0.5 km/h) and no significant canopy effect was observed on air temperature. An infection model was developed and showed that only rainfall periods which induced long LWDs inside the canopy, were favourable to M. pinodes infection under our climatic conditions and suggested a more favourable microclimate inside dense canopies.